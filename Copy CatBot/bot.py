# Load Larger LSTM network and generate text
from __future__ import print_function
import sys
import numpy as np
import pandas as pd
import string, os 
import random
import warnings
warnings.filterwarnings("ignore")
from keras.callbacks import LambdaCallback
from keras.models import Sequential
from keras.layers import Dense, Activation
from keras.layers import LSTM
from keras.optimizers import RMSprop

# ***********************************************************************
# Importing the dataset
file=pd.read_csv("C:/Users/RISHABH/Documents/GitHub/Mini/Copy CatBot/mann_ki_baat.csv",encoding="unicode_escape")

# Dropping of columns like month and year
file.drop('month', axis=1, inplace=True)
file.drop('year', axis=1, inplace=True)


# ***********************************************************************
# Merging of all the rows to generate raw text
#raw_text=list()
raw_text=''
for i in range(47):
    raw_text=raw_text+file.iloc[i,0]
    #raw_text.append(file.iloc[i,0])

#  Lower casing all the words.
raw_text = raw_text.lower()
print('text length', len(raw_text))
print(raw_text[:300])


# ***********************************************************************

# create mapping of unique chars to integers, and a reverse mapping
# Since we are training on character level, therefore we have to relate 
# each unique character to a number
chars = sorted(list(set(raw_text)))
print('total chars: ', len(chars))

char_to_int = dict((c, i) for i, c in enumerate(chars))
int_to_char = dict((i, c) for i, c in enumerate(chars))

# ***********************************************************************

# Split up into subsequences
# Creates an array of sentence data with the length maxlen 
# Create an array with the next character.

maxlen = 40
step = 3
sentences = []
next_chars = []
for i in range(0, len(raw_text) - maxlen, step):
    sentences.append(raw_text[i: i + maxlen])
    next_chars.append(raw_text[i + maxlen])
print('nb sequences:', len(sentences))

# ***********************************************************************

#  reshape our data in a format we can pass to the Keras LSTM 
# The shape look like [samples, time steps, features]
x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool)
for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        x[i, t, char_to_int[char]] = 1
    y[i, char_to_int[next_chars[i]]] = 1
    
# ***********************************************************************

# Define the LSTM model
model = Sequential()
model.add(LSTM(128, input_shape=(maxlen, len(chars))))
model.add(Dense(len(chars)))
model.add(Activation('softmax'))

optimizer = RMSprop(lr=0.01)
model.compile(loss='categorical_crossentropy', optimizer=optimizer)

# ***********************************************************************

# Samples an index from a probability array with some temperature.
# Function from keras documentation

def sample(preds, temperature=1.0):
    # helper function to sample an index from a probability array
    preds = np.asarray(preds).astype('float64')
    preds = np.log(preds) / temperature
    exp_preds = np.exp(preds)
    preds = exp_preds / np.sum(exp_preds)
    probas = np.random.multinomial(1, preds, 1)
    return np.argmax(probas)

# ***********************************************************************

# Callback function to print predicted text generated by our LSTM
    
def on_epoch_end(epoch, logs):
    # Function invoked at end of each epoch. Prints generated text.
    print()
    print('----- Generating text after Epoch: %d' % epoch)

    start_index = random.randint(0, len(raw_text) - maxlen - 1)
    for diversity in [0.2, 0.5, 1.0, 1.2]:
        print('----- diversity:', diversity)

        generated = ''
        sentence = raw_text[start_index: start_index + maxlen]
        generated += sentence
        print('----- Generating with seed: "' + sentence + '"')
        sys.stdout.write(generated)

        for i in range(400):
            x_pred = np.zeros((1, maxlen, len(chars)))
            for t, char in enumerate(sentence):
                x_pred[0, t, char_to_int[char]] = 1.

            preds = model.predict(x_pred, verbose=0)[0]
            next_index = sample(preds, diversity)
            next_char = int_to_char[next_index]

            generated += next_char
            sentence = sentence[1:] + next_char

            sys.stdout.write(next_char)
            sys.stdout.flush()
        print()
print_callback = LambdaCallback(on_epoch_end=on_epoch_end)

# ***********************************************************************

#  Defining callbacks and training the model
from keras.callbacks import ModelCheckpoint

filepath = "weights.hdf5"
checkpoint = ModelCheckpoint(filepath, monitor='loss',
                             verbose=1, save_best_only=True,
                             mode='min')


# ***********************************************************************

from keras.callbacks import ReduceLROnPlateau
reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2,
                              patience=1, min_lr=0.001)


callbacks = [print_callback, checkpoint, reduce_lr]

# ***********************************************************************

model.fit(x, y, batch_size=128, epochs=5, callbacks=callbacks)

# ***********************************************************************

# Generate new text

def generate_text(length, diversity):
    # Get random starting text
    start_index = random.randint(0, len(raw_text) - maxlen - 1)
    generated = ''
    sentence = raw_text[start_index: start_index + maxlen]
    generated += sentence
    for i in range(length):
            x_pred = np.zeros((1, maxlen, len(chars)))
            for t, char in enumerate(sentence):
                x_pred[0, t, char_to_int[char]] = 1.

            preds = model.predict(x_pred, verbose=0)[0]
            next_index = sample(preds, diversity)
            next_char = int_to_char[next_index]

            generated += next_char
            sentence = sentence[1:] + next_char
    return generated



print(generate_text(500, 0.2))

